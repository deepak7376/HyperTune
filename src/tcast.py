# -*- coding: utf-8 -*-
"""rnn_optimization_using_deap_package.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17FHqIaxZjgBMnuvjwohC_V6h_rUa1Coh
"""

!pip install deap



"""
main theme of the of the projecet is to implentment 
various optimization technique

compare :
1- random search method
2- Baysian optimizatio
3- Genetic algorithms

"""




def evaluate(individual):
        print('\n--evaluation--')
        
        num_params = len(func_seq)
        #n = len(genome)
        input_layer_flag = False
        return_flag = False

        model = Sequential() 

        for i in range(IND_SIZE):
            
            index = i*num_params
            
            if individual[index] > 0:
                if input_layer_flag==False:
                    model.add(LSTM(individual[index+1],activation=individual[index+2],
                                input_shape=(lags, features),
                                kernel_regularizer= keras.regularizers.l2(0.0001),
                                    return_sequences=True))
            
                    input_layer_flag=True
            
                else:
                    model.add(LSTM(individual[index+1],activation=individual[index+2],
                                kernel_regularizer= keras.regularizers.l2(0.0001), 
                                return_sequences=True))
            
                return_flag=True
        
        # final layer
        model.add(Flatten())
        model.add(Dense(1))
        model.compile(loss='mean_squared_error', optimizer='adam')
       
        model.fit(X_train, y_train, batch_size = 2, epochs=10 ,verbose=1)
        y_pred = model.predict(X_val)
        #score, acc = model.evaluate(X_val, y_val)
        plt.plot(y_pred)
        plt.plot(y_val)
        
        return mean_absolute_percentage_error(y_val, y_pred)

import numpy as np
from random import randrange

x = np.random.randn(10, 4)
tuple([randrange(m) for m in x.shape])
y = np.arange(4)
y[:, np.newaxis, np.newaxis]

def evaluate(genome):
        # if not self.is_compatible_genome(genome):
        #     raise ValueError("Invalid genome for specified configs")
        model = Sequential()
        dim = 0
        offset = 0
        if self.convolution_layers > 0:
            dim = min(self.input_shape[:-1]) # keep track of smallest dimension
        input_layer = True
        for i in range(self.convolution_layers):
            if genome[offset]:
                convolution = None
                if input_layer:
                    convolution = Convolution2D(
                        genome[offset + 1], (3, 3),
                        padding='same',
                        input_shape=self.input_shape
                    )
                    input_layer = False
                else:
                    convolution = Convolution2D(
                        genome[offset + 1], (3, 3),
                        padding='same'
                    )
                model.add(convolution)
                if genome[offset + 2]:
                    model.add(BatchNormalization())
                model.add(Activation(self.activation[genome[offset + 3]]))
                model.add(Dropout(float(genome[offset + 4] / 20.0)))
                max_pooling_type = genome[offset + 5]
                # must be large enough for a convolution
                if max_pooling_type == 1 and dim >= 5:
                    model.add(MaxPooling2D(pool_size=(2, 2), padding="same"))
                    dim = int(math.ceil(dim / 2))
            offset += self.convolution_layer_size

        if not input_layer:
            model.add(Flatten())

        for i in range(self.dense_layers):
            if genome[offset]:
                dense = None
                if input_layer:
                    dense = Dense(genome[offset + 1], input_shape=self.input_shape)
                    input_layer = False
                else:
                    dense = Dense(genome[offset + 1])
                model.add(dense)
                if genome[offset + 2]:
                    model.add(BatchNormalization())
                model.add(Activation(self.activation[genome[offset + 3]]))
                model.add(Dropout(float(genome[offset + 4] / 20.0)))
            offset += self.dense_layer_size
        
        model.add(Dense(self.n_classes, activation='softmax'))
        model.compile(loss='categorical_crossentropy',
            optimizer=self.optimizer[genome[offset]],
            metrics=["accuracy"])
        return model

x = [1, 512, 'tanh', 0, 32, 'tanh', 0, 512, 'tanh', 1, 256, 'relu', 0, 256, 'relu']
evaluate(x)